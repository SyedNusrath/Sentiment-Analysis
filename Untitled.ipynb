{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "my_stop=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'DMV Customer Feedback - Voting Comments.xlsx',sheetname='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Type of Survey</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1584331-f0cb-4ea2-a6a1-5ae43ba6c243</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-02 10:28:50</td>\n",
       "      <td>the fees are  to high as it is. why does it co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc842998-2241-424b-8c47-0f4d8908696c</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-03 21:19:14</td>\n",
       "      <td>Love how DMV has piggy bank for everything. Fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960d84fc-4850-4ca3-b2d9-8c7e63542ff4</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-05 12:06:09</td>\n",
       "      <td>the registration process / security questions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be16186c-816c-4aea-97eb-6b400a4c9cc0</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-07 15:07:41</td>\n",
       "      <td>Jerry brown can fuck off and die!! He is a fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b23a468a-fdba-4ad5-9600-b026a7abe654</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-08 12:40:28</td>\n",
       "      <td>Links need to be seen better. Registration to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Survey ID Type of Survey                Date  \\\n",
       "0  c1584331-f0cb-4ea2-a6a1-5ae43ba6c243    DMV Website 2018-01-02 10:28:50   \n",
       "1  fc842998-2241-424b-8c47-0f4d8908696c    DMV Website 2018-01-03 21:19:14   \n",
       "2  960d84fc-4850-4ca3-b2d9-8c7e63542ff4    DMV Website 2018-01-05 12:06:09   \n",
       "3  be16186c-816c-4aea-97eb-6b400a4c9cc0    DMV Website 2018-01-07 15:07:41   \n",
       "4  b23a468a-fdba-4ad5-9600-b026a7abe654    DMV Website 2018-01-08 12:40:28   \n",
       "\n",
       "                                             Comment  \n",
       "0  the fees are  to high as it is. why does it co...  \n",
       "1  Love how DMV has piggy bank for everything. Fe...  \n",
       "2  the registration process / security questions ...  \n",
       "3  Jerry brown can fuck off and die!! He is a fuc...  \n",
       "4  Links need to be seen better. Registration to ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_cleaning(text):    \n",
    "    # split into sentences\n",
    "    words  = word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    \n",
    "    # remove stop words in sentence\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    return (\" \".join(str(x) for x in words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['Comment'] = data['Comment'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survey ID</th>\n",
       "      <th>Type of Survey</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1584331-f0cb-4ea2-a6a1-5ae43ba6c243</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-02 10:28:50</td>\n",
       "      <td>fees high cost use online services registratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fc842998-2241-424b-8c47-0f4d8908696c</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-03 21:19:14</td>\n",
       "      <td>love dmv piggy bank everything fees added fee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960d84fc-4850-4ca3-b2d9-8c7e63542ff4</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-05 12:06:09</td>\n",
       "      <td>registration process security questions involv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>be16186c-816c-4aea-97eb-6b400a4c9cc0</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-07 15:07:41</td>\n",
       "      <td>jerry brown fuck die fucking thief represent v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b23a468a-fdba-4ad5-9600-b026a7abe654</td>\n",
       "      <td>DMV Website</td>\n",
       "      <td>2018-01-08 12:40:28</td>\n",
       "      <td>links need seen better registration vote quest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Survey ID Type of Survey                Date  \\\n",
       "0  c1584331-f0cb-4ea2-a6a1-5ae43ba6c243    DMV Website 2018-01-02 10:28:50   \n",
       "1  fc842998-2241-424b-8c47-0f4d8908696c    DMV Website 2018-01-03 21:19:14   \n",
       "2  960d84fc-4850-4ca3-b2d9-8c7e63542ff4    DMV Website 2018-01-05 12:06:09   \n",
       "3  be16186c-816c-4aea-97eb-6b400a4c9cc0    DMV Website 2018-01-07 15:07:41   \n",
       "4  b23a468a-fdba-4ad5-9600-b026a7abe654    DMV Website 2018-01-08 12:40:28   \n",
       "\n",
       "                                             Comment  \n",
       "0  fees high cost use online services registratio...  \n",
       "1  love dmv piggy bank everything fees added fee ...  \n",
       "2  registration process security questions involv...  \n",
       "3  jerry brown fuck die fucking thief represent v...  \n",
       "4  links need seen better registration vote quest...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stop=set(stopwords.words('english')+list(punctuation))\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case_numbers = data['Survey ID']\n",
    "def findSenti(cases):\n",
    "    pos_neg=[]\n",
    "    case_number=[]\n",
    "    comments = []\n",
    "    for i,sent in enumerate(cases):\n",
    "        words=word_tokenize(sent)\n",
    "        words=[w for w in words if w not in my_stop]      \n",
    "        neg_words=[]\n",
    "        pos_words=[]\n",
    "        for index,word in enumerate(words):\n",
    "            if analyzer.polarity_scores(word)['neg']> 0:\n",
    "                if word not in neg_words:\n",
    "                    neg_words.append(word)             \n",
    "            elif TextBlob(word).sentiment.polarity<-0.5:\n",
    "                if word not in neg_words:\n",
    "                    neg_words.append(word)\n",
    "            if analyzer.polarity_scores(word)['pos']> 0:\n",
    "                if word not in pos_words:\n",
    "                    pos_words.append(word)           \n",
    "            elif TextBlob(word).sentiment.polarity > 0.5:\n",
    "                if word not in pos_words:\n",
    "                    pos_words.append(word)\n",
    "        case_number.append(case_numbers[i])\n",
    "        print(i,len(neg_words),len(pos_words))\n",
    "        if len(neg_words) > len(pos_words):\n",
    "            pos_neg.append('neg')\n",
    "        elif len(pos_words) > len(neg_words):\n",
    "            pos_neg.append('pos')\n",
    "        else:\n",
    "            pos_neg.append('netural')\n",
    "        comments.append(sent)\n",
    "    return pd.DataFrame({'case_id':case_number,'sentiment':pos_neg,'Comment':comments})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 1\n",
      "1 6 6\n",
      "2 1 2\n",
      "3 7 1\n",
      "4 0 4\n",
      "5 1 0\n",
      "6 0 3\n",
      "7 2 1\n",
      "8 0 0\n",
      "9 0 1\n",
      "10 0 2\n",
      "11 2 1\n",
      "12 1 1\n",
      "13 1 4\n",
      "14 1 0\n",
      "15 0 3\n",
      "16 3 2\n",
      "17 2 0\n",
      "18 2 0\n",
      "19 2 0\n",
      "20 0 2\n",
      "21 2 2\n",
      "22 3 4\n",
      "23 1 1\n",
      "24 2 1\n",
      "25 0 3\n",
      "26 1 3\n",
      "27 1 2\n",
      "28 3 0\n",
      "29 0 0\n",
      "30 1 6\n",
      "31 0 3\n",
      "32 1 1\n",
      "33 1 2\n",
      "34 1 4\n",
      "35 2 3\n",
      "36 1 0\n",
      "37 1 4\n",
      "38 0 3\n",
      "39 4 5\n",
      "40 0 1\n",
      "41 0 0\n",
      "42 1 1\n",
      "43 1 0\n",
      "44 1 0\n",
      "45 1 2\n",
      "46 0 1\n",
      "47 3 1\n",
      "48 0 4\n",
      "49 6 1\n",
      "50 1 1\n",
      "51 8 3\n",
      "52 3 1\n",
      "53 0 3\n",
      "54 0 1\n",
      "55 2 2\n",
      "56 1 3\n",
      "57 0 1\n",
      "58 4 2\n",
      "59 3 0\n",
      "60 0 1\n",
      "61 3 0\n",
      "62 3 1\n",
      "63 7 3\n",
      "64 0 2\n",
      "65 2 0\n",
      "66 0 2\n",
      "67 3 1\n",
      "68 3 0\n",
      "69 0 1\n",
      "70 4 1\n",
      "71 1 3\n",
      "72 1 2\n",
      "73 0 2\n",
      "74 6 1\n",
      "75 1 1\n",
      "76 2 0\n",
      "77 2 2\n",
      "78 3 0\n",
      "79 0 1\n",
      "80 0 1\n",
      "81 1 0\n",
      "82 1 2\n",
      "83 0 3\n",
      "84 3 1\n",
      "85 1 3\n",
      "86 0 1\n",
      "87 3 2\n",
      "88 0 0\n",
      "89 7 1\n",
      "90 1 2\n",
      "91 0 1\n",
      "92 1 1\n",
      "93 0 1\n",
      "94 5 1\n",
      "95 0 1\n",
      "96 1 2\n",
      "97 2 3\n",
      "98 2 0\n",
      "99 4 0\n",
      "100 0 1\n",
      "101 0 1\n",
      "102 1 0\n",
      "103 0 0\n",
      "104 0 0\n",
      "105 4 4\n",
      "106 1 3\n",
      "107 7 1\n",
      "108 2 1\n",
      "109 2 2\n",
      "110 2 4\n",
      "111 3 3\n",
      "112 3 2\n",
      "113 4 3\n",
      "114 0 0\n",
      "115 1 3\n",
      "116 2 3\n",
      "117 1 2\n",
      "118 1 2\n",
      "119 1 3\n",
      "120 2 2\n",
      "121 0 1\n",
      "122 0 0\n",
      "123 3 2\n",
      "124 0 1\n",
      "125 0 0\n",
      "126 0 2\n",
      "127 1 1\n",
      "128 0 1\n",
      "129 1 0\n",
      "130 1 2\n",
      "131 0 0\n",
      "132 0 1\n",
      "133 2 1\n",
      "134 0 1\n",
      "135 0 0\n",
      "136 2 3\n",
      "137 1 0\n",
      "138 1 6\n",
      "139 1 0\n",
      "140 1 3\n",
      "141 2 0\n",
      "142 3 3\n",
      "143 1 0\n",
      "144 3 2\n",
      "145 0 1\n",
      "146 0 5\n",
      "147 0 1\n",
      "148 2 3\n",
      "149 2 0\n",
      "150 1 0\n",
      "151 0 0\n",
      "152 0 3\n",
      "153 0 1\n",
      "154 1 3\n",
      "155 1 4\n",
      "156 2 1\n",
      "157 1 0\n",
      "158 3 5\n",
      "159 0 1\n",
      "160 4 2\n",
      "161 1 1\n",
      "162 0 0\n",
      "163 5 2\n",
      "164 0 1\n",
      "165 0 2\n",
      "166 0 1\n",
      "167 0 0\n",
      "168 0 3\n",
      "169 1 4\n",
      "170 1 1\n",
      "171 1 0\n",
      "172 2 3\n",
      "173 2 1\n",
      "174 1 1\n",
      "175 1 1\n",
      "176 2 1\n",
      "177 0 2\n",
      "178 1 1\n",
      "179 2 1\n",
      "180 1 0\n",
      "181 0 0\n",
      "182 0 3\n",
      "183 0 0\n",
      "184 0 0\n",
      "185 1 2\n",
      "186 2 2\n",
      "187 2 1\n",
      "188 0 1\n",
      "189 5 4\n",
      "190 0 0\n",
      "191 0 5\n",
      "192 1 0\n",
      "193 1 1\n",
      "194 0 3\n",
      "195 0 1\n",
      "196 1 0\n",
      "197 0 1\n",
      "198 1 3\n",
      "199 1 1\n",
      "200 1 1\n",
      "201 2 8\n",
      "202 1 1\n",
      "203 0 1\n",
      "204 1 0\n",
      "205 3 2\n",
      "206 0 1\n",
      "207 2 6\n",
      "208 1 0\n",
      "209 0 0\n",
      "210 2 0\n",
      "211 1 0\n",
      "212 3 4\n",
      "213 5 1\n",
      "214 1 3\n",
      "215 2 1\n",
      "216 1 1\n",
      "217 1 3\n",
      "218 1 0\n",
      "219 2 1\n",
      "220 1 0\n",
      "221 2 6\n",
      "222 0 1\n",
      "223 1 2\n",
      "224 0 0\n",
      "225 0 0\n",
      "226 3 0\n",
      "227 2 4\n",
      "228 3 1\n",
      "229 1 2\n",
      "230 1 0\n",
      "231 3 2\n",
      "232 1 0\n",
      "233 0 3\n",
      "234 0 0\n",
      "235 0 2\n",
      "236 1 1\n",
      "237 1 1\n",
      "238 3 3\n",
      "239 2 0\n",
      "240 0 4\n",
      "241 8 0\n",
      "242 0 1\n",
      "243 0 1\n",
      "244 0 5\n",
      "245 1 1\n",
      "246 0 1\n",
      "247 0 2\n",
      "248 0 2\n",
      "249 1 1\n",
      "250 1 1\n",
      "251 1 2\n",
      "252 5 3\n",
      "253 0 1\n",
      "254 5 4\n",
      "255 1 3\n",
      "256 0 0\n",
      "257 2 1\n",
      "258 0 1\n",
      "259 0 0\n",
      "260 1 0\n",
      "261 1 2\n",
      "262 2 0\n",
      "263 1 1\n",
      "264 1 0\n",
      "265 2 1\n",
      "266 4 2\n",
      "267 2 2\n",
      "268 3 0\n",
      "269 0 2\n",
      "270 0 1\n",
      "271 1 2\n",
      "272 2 4\n",
      "273 3 1\n",
      "274 1 0\n",
      "275 0 0\n",
      "276 0 2\n",
      "277 1 4\n",
      "278 1 1\n",
      "279 3 3\n",
      "280 2 3\n",
      "281 0 0\n",
      "282 4 3\n",
      "283 0 2\n",
      "284 2 3\n",
      "285 1 1\n",
      "286 2 2\n",
      "287 0 2\n",
      "288 0 2\n",
      "289 1 0\n",
      "290 2 2\n",
      "291 0 1\n",
      "292 0 0\n",
      "293 1 1\n",
      "294 2 3\n",
      "295 1 2\n",
      "296 2 5\n",
      "297 0 2\n",
      "298 1 0\n",
      "299 1 2\n",
      "300 1 1\n",
      "301 0 0\n",
      "302 0 1\n",
      "303 0 1\n",
      "304 1 4\n",
      "305 2 1\n",
      "306 2 1\n",
      "307 3 1\n",
      "308 0 4\n",
      "309 0 1\n",
      "310 2 3\n",
      "311 3 3\n",
      "312 1 1\n",
      "313 3 0\n",
      "314 4 5\n",
      "315 0 3\n",
      "316 4 2\n",
      "317 3 0\n",
      "318 0 0\n",
      "319 1 0\n",
      "320 1 1\n",
      "321 4 2\n",
      "322 0 3\n",
      "323 4 3\n",
      "324 0 1\n",
      "325 0 1\n",
      "326 0 3\n",
      "327 2 2\n",
      "328 0 3\n",
      "329 2 0\n",
      "330 1 2\n",
      "331 1 3\n",
      "332 1 1\n",
      "333 1 1\n",
      "334 5 4\n",
      "335 1 3\n",
      "336 1 3\n",
      "337 0 5\n",
      "338 6 2\n",
      "339 0 2\n",
      "340 4 0\n",
      "341 0 1\n",
      "342 0 2\n",
      "343 0 0\n",
      "344 1 1\n",
      "345 0 1\n",
      "346 0 1\n",
      "347 2 1\n",
      "348 2 1\n",
      "349 1 2\n",
      "350 0 1\n",
      "351 1 3\n",
      "352 1 0\n",
      "353 1 4\n",
      "354 0 4\n",
      "355 0 0\n",
      "356 0 1\n",
      "357 1 3\n",
      "358 3 7\n",
      "359 1 1\n",
      "360 1 1\n",
      "361 0 1\n",
      "362 0 4\n",
      "363 1 1\n",
      "364 0 1\n",
      "365 2 1\n",
      "366 0 1\n",
      "367 0 1\n",
      "368 2 2\n",
      "369 0 4\n",
      "370 0 3\n",
      "371 2 3\n",
      "372 1 0\n",
      "373 0 1\n",
      "374 1 3\n",
      "375 1 1\n",
      "376 2 0\n",
      "377 2 5\n",
      "378 2 0\n",
      "379 0 1\n",
      "380 0 2\n",
      "381 2 0\n",
      "382 3 0\n",
      "383 0 1\n",
      "384 1 1\n",
      "385 2 8\n",
      "386 3 2\n",
      "387 1 1\n",
      "388 0 1\n",
      "389 1 1\n",
      "390 1 0\n",
      "391 1 0\n",
      "392 0 2\n",
      "393 4 2\n",
      "394 1 1\n",
      "395 1 2\n",
      "396 1 1\n",
      "397 1 4\n",
      "398 1 1\n",
      "399 0 0\n",
      "400 0 4\n",
      "401 1 0\n",
      "402 2 3\n",
      "403 0 2\n",
      "404 0 1\n",
      "405 3 1\n",
      "406 0 1\n",
      "407 2 2\n",
      "408 1 0\n",
      "409 2 6\n",
      "410 0 4\n",
      "411 2 0\n",
      "412 2 1\n",
      "413 0 1\n",
      "414 1 4\n",
      "415 1 1\n",
      "416 1 1\n",
      "417 1 4\n",
      "418 0 2\n",
      "419 0 1\n",
      "420 2 1\n",
      "421 0 2\n",
      "422 0 2\n",
      "423 0 1\n",
      "424 0 0\n",
      "425 0 3\n",
      "426 0 0\n",
      "427 1 1\n",
      "428 1 1\n",
      "429 1 2\n",
      "430 0 2\n",
      "431 4 3\n",
      "432 0 1\n",
      "433 4 2\n",
      "434 1 2\n",
      "435 0 1\n",
      "436 0 0\n",
      "437 0 2\n",
      "438 2 0\n",
      "439 0 4\n",
      "440 0 1\n",
      "441 1 2\n",
      "442 0 0\n",
      "443 0 5\n",
      "444 1 1\n",
      "445 2 1\n",
      "446 1 1\n",
      "447 3 0\n",
      "448 0 1\n",
      "449 2 5\n",
      "450 2 2\n",
      "451 1 1\n",
      "452 0 2\n",
      "453 4 2\n",
      "454 0 2\n",
      "455 1 2\n",
      "456 1 0\n",
      "457 0 0\n",
      "458 1 0\n",
      "459 3 2\n",
      "460 0 2\n",
      "461 3 5\n",
      "462 0 0\n",
      "463 0 1\n",
      "464 3 0\n",
      "465 1 0\n",
      "466 0 2\n",
      "467 2 3\n",
      "468 3 3\n",
      "469 0 1\n",
      "470 0 2\n",
      "471 2 2\n",
      "472 0 1\n",
      "473 2 2\n",
      "474 0 0\n",
      "475 1 3\n",
      "476 1 3\n",
      "477 1 3\n",
      "478 0 2\n",
      "479 1 3\n",
      "480 1 1\n",
      "481 0 0\n",
      "482 1 0\n",
      "483 1 2\n",
      "484 2 0\n",
      "485 0 0\n",
      "486 1 0\n",
      "487 1 1\n",
      "488 1 0\n",
      "489 1 0\n",
      "490 1 0\n",
      "491 3 3\n",
      "492 1 2\n",
      "493 0 2\n",
      "494 2 3\n",
      "495 2 1\n",
      "496 0 1\n",
      "497 2 1\n",
      "498 2 0\n",
      "499 0 2\n",
      "500 0 0\n",
      "501 0 0\n",
      "502 1 4\n",
      "503 1 0\n",
      "504 1 0\n",
      "505 0 0\n",
      "506 2 1\n",
      "507 1 3\n",
      "508 4 2\n",
      "509 6 5\n",
      "510 1 0\n",
      "511 1 4\n",
      "512 1 0\n",
      "513 1 1\n",
      "514 1 2\n",
      "515 1 1\n",
      "516 0 3\n",
      "517 0 0\n",
      "518 0 4\n",
      "519 1 2\n",
      "520 0 0\n",
      "521 1 0\n",
      "522 2 2\n",
      "523 2 3\n",
      "524 2 1\n",
      "525 1 2\n",
      "526 2 4\n",
      "527 2 1\n",
      "528 1 2\n",
      "529 2 2\n",
      "530 2 1\n",
      "531 0 3\n",
      "532 0 1\n",
      "533 3 0\n",
      "534 1 3\n",
      "535 2 1\n",
      "536 1 0\n",
      "537 2 4\n",
      "538 1 2\n",
      "539 0 3\n",
      "540 0 1\n",
      "541 0 1\n",
      "542 2 1\n",
      "543 1 1\n",
      "544 1 1\n",
      "545 1 0\n",
      "546 0 1\n",
      "547 0 0\n",
      "548 0 1\n",
      "549 0 2\n",
      "550 0 1\n",
      "551 2 0\n",
      "552 1 1\n",
      "553 3 0\n",
      "554 1 0\n",
      "555 1 0\n",
      "556 7 2\n",
      "557 0 1\n",
      "558 1 2\n",
      "559 1 3\n",
      "560 1 1\n",
      "561 0 0\n",
      "562 1 4\n",
      "563 2 0\n",
      "564 1 0\n",
      "565 3 4\n",
      "566 0 3\n",
      "567 0 1\n",
      "568 2 3\n",
      "569 0 3\n",
      "570 1 0\n",
      "571 0 0\n",
      "572 0 0\n",
      "573 1 4\n",
      "574 0 1\n",
      "575 1 4\n",
      "576 1 3\n",
      "577 2 3\n",
      "578 2 1\n",
      "579 2 2\n",
      "580 0 2\n",
      "581 0 2\n",
      "582 3 1\n",
      "583 0 0\n",
      "584 2 1\n",
      "585 1 0\n",
      "586 2 5\n",
      "587 1 2\n",
      "588 1 0\n",
      "589 0 0\n",
      "590 1 1\n",
      "591 0 2\n",
      "592 1 0\n",
      "593 2 2\n",
      "594 0 0\n",
      "595 1 1\n",
      "596 2 0\n",
      "597 6 0\n",
      "598 0 4\n",
      "599 0 1\n",
      "600 0 0\n",
      "601 1 3\n",
      "602 3 2\n",
      "603 0 3\n",
      "604 2 2\n",
      "605 2 3\n",
      "606 0 1\n",
      "607 0 4\n",
      "608 2 1\n",
      "609 0 0\n",
      "610 2 1\n",
      "611 0 3\n",
      "612 1 3\n",
      "613 0 4\n",
      "614 0 6\n",
      "615 2 0\n",
      "616 0 1\n",
      "617 0 1\n",
      "618 1 5\n",
      "619 1 1\n",
      "620 1 0\n",
      "621 1 4\n",
      "622 0 1\n",
      "623 3 1\n",
      "624 2 5\n",
      "625 3 2\n",
      "626 1 2\n",
      "627 0 2\n",
      "628 3 2\n",
      "629 3 1\n",
      "630 1 2\n",
      "631 0 0\n",
      "632 1 1\n",
      "633 0 2\n",
      "634 0 3\n",
      "635 9 2\n",
      "636 3 1\n",
      "637 1 2\n",
      "638 2 0\n",
      "639 1 2\n",
      "640 2 4\n",
      "641 1 5\n",
      "642 0 1\n",
      "643 1 2\n",
      "644 1 1\n",
      "645 1 3\n",
      "646 0 4\n",
      "647 0 0\n",
      "648 1 5\n",
      "649 3 1\n",
      "650 1 4\n",
      "651 3 1\n",
      "652 0 1\n",
      "653 4 0\n",
      "654 0 1\n",
      "655 0 0\n",
      "656 1 3\n",
      "657 1 5\n",
      "658 1 6\n",
      "659 1 0\n",
      "660 0 7\n",
      "661 2 1\n",
      "662 0 1\n",
      "663 0 0\n",
      "664 1 1\n",
      "665 1 1\n",
      "666 1 1\n",
      "667 1 3\n",
      "668 2 2\n",
      "669 0 2\n",
      "670 0 0\n",
      "671 4 0\n",
      "672 3 1\n",
      "673 0 3\n",
      "674 2 0\n",
      "675 0 0\n",
      "676 0 1\n",
      "677 3 2\n",
      "678 0 4\n",
      "679 1 0\n",
      "680 0 2\n",
      "681 5 3\n",
      "682 0 2\n",
      "683 0 0\n",
      "684 1 0\n",
      "685 1 3\n",
      "686 2 1\n",
      "687 0 0\n",
      "688 0 2\n",
      "689 1 2\n",
      "690 1 4\n",
      "691 4 1\n",
      "692 2 3\n",
      "693 2 1\n",
      "694 1 0\n",
      "695 2 1\n",
      "696 1 2\n",
      "697 2 1\n",
      "698 1 2\n",
      "699 0 3\n",
      "700 1 1\n",
      "701 0 2\n",
      "702 0 3\n",
      "703 1 1\n",
      "704 2 1\n",
      "705 1 2\n",
      "706 0 1\n",
      "707 1 0\n",
      "708 0 1\n",
      "709 0 1\n",
      "710 0 5\n",
      "711 2 4\n",
      "712 0 0\n",
      "713 2 1\n",
      "714 3 0\n",
      "715 0 0\n",
      "716 1 0\n",
      "717 0 2\n",
      "718 0 1\n",
      "719 1 0\n",
      "720 2 0\n",
      "721 2 1\n",
      "722 1 0\n",
      "723 0 2\n",
      "724 0 2\n",
      "725 0 2\n",
      "726 0 0\n",
      "727 1 3\n",
      "728 0 1\n",
      "729 2 0\n",
      "730 0 0\n",
      "731 0 2\n",
      "732 0 1\n",
      "733 0 1\n",
      "734 2 7\n",
      "735 1 1\n",
      "736 3 4\n",
      "737 1 0\n",
      "738 0 1\n",
      "739 0 0\n",
      "740 0 0\n",
      "741 0 5\n",
      "742 0 1\n",
      "743 5 2\n",
      "744 1 1\n",
      "745 1 3\n",
      "746 0 0\n",
      "747 0 1\n",
      "748 1 1\n",
      "749 4 0\n",
      "750 5 2\n",
      "751 3 3\n",
      "752 2 2\n",
      "753 0 0\n",
      "754 2 1\n",
      "755 0 2\n",
      "756 1 2\n",
      "757 1 4\n",
      "758 2 4\n",
      "759 0 2\n",
      "760 1 1\n",
      "761 2 4\n",
      "762 1 2\n",
      "763 1 1\n",
      "764 3 4\n",
      "765 0 2\n",
      "766 1 1\n",
      "767 0 1\n",
      "768 0 1\n",
      "769 2 2\n",
      "770 0 0\n",
      "771 0 1\n",
      "772 1 3\n",
      "773 0 3\n",
      "774 0 0\n",
      "775 0 0\n",
      "776 0 6\n",
      "777 0 5\n",
      "778 1 2\n",
      "779 0 4\n",
      "780 0 0\n",
      "781 0 2\n",
      "782 0 1\n",
      "783 4 0\n",
      "784 1 0\n",
      "785 0 0\n",
      "786 1 2\n",
      "787 0 0\n",
      "788 0 0\n",
      "789 1 0\n",
      "790 3 1\n",
      "791 3 3\n",
      "792 2 4\n",
      "793 1 1\n",
      "794 0 5\n",
      "795 1 1\n",
      "796 3 7\n",
      "797 0 3\n",
      "798 3 1\n",
      "799 1 0\n",
      "800 3 1\n",
      "801 2 3\n",
      "802 2 2\n",
      "803 3 2\n",
      "804 2 6\n",
      "805 4 6\n",
      "806 3 0\n",
      "807 1 8\n",
      "808 5 4\n",
      "809 2 5\n",
      "810 1 0\n",
      "811 0 2\n",
      "812 1 0\n",
      "813 0 2\n",
      "814 4 2\n",
      "815 2 3\n",
      "816 0 1\n",
      "817 0 0\n",
      "818 3 4\n",
      "819 1 0\n",
      "820 1 1\n",
      "821 0 2\n",
      "822 0 2\n",
      "823 1 3\n",
      "824 4 1\n",
      "825 5 3\n",
      "826 0 0\n",
      "827 0 2\n",
      "828 3 0\n",
      "829 0 0\n",
      "830 0 0\n",
      "831 3 1\n",
      "832 2 2\n",
      "833 1 3\n",
      "834 4 0\n",
      "835 3 2\n",
      "836 0 0\n",
      "837 1 3\n",
      "838 0 2\n",
      "839 3 1\n",
      "840 6 1\n",
      "841 1 1\n",
      "842 1 1\n",
      "843 0 0\n",
      "844 0 2\n",
      "845 5 8\n",
      "846 0 1\n",
      "847 0 2\n",
      "848 1 1\n",
      "849 0 0\n",
      "850 1 0\n",
      "851 1 5\n",
      "852 1 3\n",
      "853 3 1\n",
      "854 0 2\n",
      "855 2 3\n",
      "856 0 1\n",
      "857 1 3\n",
      "858 1 3\n",
      "859 1 2\n",
      "860 2 1\n",
      "861 0 0\n",
      "862 0 0\n",
      "863 1 0\n",
      "864 1 1\n",
      "865 0 1\n",
      "866 0 1\n",
      "867 0 0\n",
      "868 2 2\n",
      "869 3 0\n",
      "870 1 2\n",
      "871 3 5\n",
      "872 1 1\n",
      "873 2 0\n",
      "874 0 5\n",
      "875 2 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>case_id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fees high cost use online services registratio...</td>\n",
       "      <td>c1584331-f0cb-4ea2-a6a1-5ae43ba6c243</td>\n",
       "      <td>netural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love dmv piggy bank everything fees added fee ...</td>\n",
       "      <td>fc842998-2241-424b-8c47-0f4d8908696c</td>\n",
       "      <td>netural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>registration process security questions involv...</td>\n",
       "      <td>960d84fc-4850-4ca3-b2d9-8c7e63542ff4</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jerry brown fuck die fucking thief represent v...</td>\n",
       "      <td>be16186c-816c-4aea-97eb-6b400a4c9cc0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>links need seen better registration vote quest...</td>\n",
       "      <td>b23a468a-fdba-4ad5-9600-b026a7abe654</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  fees high cost use online services registratio...   \n",
       "1  love dmv piggy bank everything fees added fee ...   \n",
       "2  registration process security questions involv...   \n",
       "3  jerry brown fuck die fucking thief represent v...   \n",
       "4  links need seen better registration vote quest...   \n",
       "\n",
       "                                case_id sentiment  \n",
       "0  c1584331-f0cb-4ea2-a6a1-5ae43ba6c243   netural  \n",
       "1  fc842998-2241-424b-8c47-0f4d8908696c   netural  \n",
       "2  960d84fc-4850-4ca3-b2d9-8c7e63542ff4       pos  \n",
       "3  be16186c-816c-4aea-97eb-6b400a4c9cc0       neg  \n",
       "4  b23a468a-fdba-4ad5-9600-b026a7abe654       pos  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cc_comments_list= data['Comment'].tolist()\n",
    "sentiment_df = findSenti(cc_comments_list)\n",
    "sentiment_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>case_id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>paper vehicle registration renewal notice sent...</td>\n",
       "      <td>e3e3538e-22dd-4855-840d-e7e71962ba74</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment  \\\n",
       "85  paper vehicle registration renewal notice sent...   \n",
       "\n",
       "                                 case_id sentiment  \n",
       "85  e3e3538e-22dd-4855-840d-e7e71962ba74       neg  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df[sentiment_df['case_id']=='e3e3538e-22dd-4855-840d-e7e71962ba74']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('sentiment1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases = data['Comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words=[]\n",
    "all_case_ids = []\n",
    "for index,case in enumerate(cases):\n",
    "    case_words =[]\n",
    "    words=word_tokenize(case)\n",
    "    words=[w for w in words if w not in my_stop]\n",
    "    for word in words:\n",
    "        if word not in case_words:\n",
    "            case_words.append(word)\n",
    "            all_words.append(word)\n",
    "            all_case_ids.append(case_numbers[index])    \n",
    "        if word not in case_words:\n",
    "            case_words.append(word)\n",
    "            all_words.append(word)\n",
    "            all_case_ids.append(case_numbers[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words_df = pd.DataFrame({'words':all_words,'case_id':all_case_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words_df.to_csv('all_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words=[]\n",
    "case_ids = []\n",
    "for index,case in enumerate(cases):\n",
    "    case_neg_words =[]\n",
    "    words=word_tokenize(case)\n",
    "    words=[w for w in words if w not in my_stop]\n",
    "    for word in words:\n",
    "        if analyzer.polarity_scores(word)['neg']> 0:\n",
    "            if word not in case_neg_words:\n",
    "                case_neg_words.append(word)\n",
    "                neg_words.append(word)\n",
    "                case_ids.append(case_numbers[index])\n",
    "        elif TextBlob(word).sentiment.polarity<-0.01:\n",
    "            if word not in case_neg_words:\n",
    "                case_neg_words.append(word)\n",
    "                neg_words.append(word)\n",
    "                case_ids.append(case_numbers[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words_df = pd.DataFrame({'words':neg_words,'case_id':case_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_words_df.to_csv('neg_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_words=[]\n",
    "case_ids = []\n",
    "for index,case in enumerate(cases):\n",
    "    case_neg_words =[]\n",
    "    words=word_tokenize(case)\n",
    "    words=[w for w in words if w not in my_stop]\n",
    "    for word in words:\n",
    "        if analyzer.polarity_scores(word)['pos']> 0:\n",
    "            if word not in case_neg_words:\n",
    "                case_neg_words.append(word)\n",
    "                pos_words.append(word)\n",
    "                case_ids.append(case_numbers[index])\n",
    "        elif TextBlob(word).sentiment.polarity > 0.01:\n",
    "            if word not in case_neg_words:\n",
    "                case_neg_words.append(word)\n",
    "                pos_words.append(word)\n",
    "                case_ids.append(case_numbers[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_words_df = pd.DataFrame({'words':pos_words,'case_id':case_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_words_df.to_csv('pos_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
